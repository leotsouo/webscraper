
import streamlit as st
import pandas as pd
import pathlib, json, re
from datetime import datetime

st.set_page_config(page_title="Dual-Source Scraper â€” Dashboard", layout="wide")
st.title("Dual-Source Web Scraper â€” Streamlit ä»‹é¢ (C)")

# ---------------------
# Paths (keep project defaults)
# ---------------------
snap_dir = pathlib.Path("data/snapshots")
diff_dir = pathlib.Path("data/diffs")
chart_dir = pathlib.Path("data/charts")

snap_dir.mkdir(parents=True, exist_ok=True)
diff_dir.mkdir(parents=True, exist_ok=True)
chart_dir.mkdir(parents=True, exist_ok=True)

# ---------------------
# Helpers
# ---------------------
def _read_csv_safe(path: pathlib.Path) -> pd.DataFrame:
    try:
        df = pd.read_csv(path, dtype=str).fillna("")
    except Exception as e:
        st.error(f"è®€å– CSV å¤±æ•—ï¼š{path} â†’ {e}")
        return pd.DataFrame()
    # unify keys
    if "pk" not in df.columns and {"source","id"}.issubset(df.columns):
        df["pk"] = df["source"].astype(str) + "::" + df["id"].astype(str)
    return df

def _parse_date_col(df: pd.DataFrame) -> pd.DataFrame:
    if "date" in df.columns:
        # accept YYYYMMDD, YYYY-MM-DD, or other; coerce invalid to NaT
        def _to_dt(x:str):
            x = str(x).strip()
            for fmt in ("%Y%m%d", "%Y-%m-%d", "%Y/%m/%d", "%Y.%m.%d"):
                try:
                    return datetime.strptime(x, fmt)
                except Exception:
                    pass
            return pd.NaT
        df["_date_dt"] = df["date"].map(_to_dt)
    return df

def _to_price_num(s: str) -> float:
    # keep digits and dot minus; e.g., "$1,234.50" -> 1234.50
    if s is None: return None
    s = str(s)
    m = re.findall(r"[-]?\d+(?:[.,]\d+)?", s.replace(",", ""))
    if not m: return None
    try:
        return float(m[0])
    except Exception:
        return None

def _ensure_price(df: pd.DataFrame) -> pd.DataFrame:
    col = "price" if "price" in df.columns else ("value" if "value" in df.columns else None)
    if col:
        df["_price_num"] = df[col].map(_to_price_num)
    return df

def _latest_snapshot_files() -> list[pathlib.Path]:
    return sorted(snap_dir.glob("snapshot_*.csv"))

def _latest_chart_images() -> list[pathlib.Path]:
    return sorted(chart_dir.glob("summary_*.png"))

# ---------------------
# Sidebar â€” source data & filters
# ---------------------
st.sidebar.header("è³‡æ–™ä¾†æºèˆ‡ç¯©é¸")
snaps = _latest_snapshot_files()
if not snaps:
    st.sidebar.info("æ‰¾ä¸åˆ°å¿«ç…§ï¼ˆdata/snapshots/snapshot_*.csvï¼‰ã€‚\nè«‹å…ˆåŸ·è¡Œ CLIï¼š\n\n`python -m src.interface.cli scrape ...`")
selected_snap = st.sidebar.selectbox("é¸æ“‡å¿«ç…§æª”", options=[s.name for s in snaps], index=len(snaps)-1 if snaps else 0)

df = pd.DataFrame()
if snaps:
    snap_path = snap_dir / selected_snap
    df = _read_csv_safe(snap_path)
    df = _parse_date_col(df)
    df = _ensure_price(df)

    # Basic search & filters
    keyword = st.sidebar.text_input("é—œéµå­—ï¼ˆtitle / url / author / categoryï¼‰", "")
    source_opts = sorted(df["source"].unique()) if "source" in df.columns else []
    sel_sources = st.sidebar.multiselect("ä¾†æºç¯©é¸", source_opts, default=source_opts)

    cat_opts = sorted([c for c in df.get("category", pd.Series([], dtype=str)).unique() if c])
    sel_cats = st.sidebar.multiselect("åˆ†é¡ç¯©é¸ï¼ˆå¯ç•™ç©ºï¼‰", cat_opts, default=cat_opts)

    # Date range filter if have dates
    if "_date_dt" in df.columns and df["_date_dt"].notna().any():
        dmin = pd.to_datetime(df["_date_dt"]).min()
        dmax = pd.to_datetime(df["_date_dt"]).max()
        drange = st.sidebar.date_input("æ—¥æœŸå€é–“", value=(dmin.date(), dmax.date()))
        if isinstance(drange, tuple) and len(drange) == 2:
            start_date, end_date = drange
        else:
            start_date, end_date = dmin.date(), dmax.date()
    else:
        start_date = end_date = None

    # Price range
    if "_price_num" in df.columns and df["_price_num"].notna().any():
        pmin = float(df["_price_num"].min())
        pmax = float(df["_price_num"].max())
        sel_pmin, sel_pmax = st.sidebar.slider("åƒ¹æ ¼å€é–“", min_value=float(pmin), max_value=float(pmax), value=(float(pmin), float(pmax)))
    else:
        sel_pmin = sel_pmax = None

    # Apply filters
    filtered = df.copy()
    if keyword:
        kw = keyword.lower()
        hay = pd.Series([""]*len(filtered))
        for c in ["title", "url", "author", "category"]:
            if c in filtered.columns:
                hay = hay + " " + filtered[c].astype(str).str.lower()
        mask_kw = hay.str.contains(kw, na=False)
        filtered = filtered[mask_kw]

    if "source" in filtered.columns and sel_sources:
        filtered = filtered[filtered["source"].isin(sel_sources)]

    if "category" in filtered.columns and sel_cats:
        filtered = filtered[filtered["category"].isin(sel_cats)]

    if start_date and end_date and "_date_dt" in filtered.columns:
        m = filtered["_date_dt"].dt.date.between(start_date, end_date)
        filtered = filtered[m]

    if sel_pmin is not None and sel_pmax is not None and "_price_num" in filtered.columns:
        m = filtered["_price_num"].between(sel_pmin, sel_pmax)
        filtered = filtered[m]

    # ---------------------
    # Top metrics
    # ---------------------
    left, mid, right = st.columns(3)
    left.metric("ç›®å‰ç­†æ•¸ (éæ¿¾å¾Œ)", len(filtered))
    mid.metric("ä¾†æºæ•¸", len(filtered["source"].unique()) if "source" in filtered.columns else 0)
    right.metric("åˆ†é¡æ•¸", len([c for c in filtered.get("category", pd.Series([], dtype=str)).unique() if c]))

    # ---------------------
    # Charts (â‰¥ 2)
    # ---------------------
    st.subheader("ğŸ“Š å¿«ç…§è¦–è¦ºåŒ–")
    c1, c2 = st.columns(2)
    with c1:
        st.caption("å„ä¾†æºç­†æ•¸åˆ†ä½ˆ")
        if "source" in filtered.columns:
            st.bar_chart(filtered["source"].value_counts().sort_values(ascending=False))
        else:
            st.info("ç„¡ source æ¬„ã€‚")

    with c2:
        if "_price_num" in filtered.columns and filtered["_price_num"].notna().sum() > 0:
            st.caption("åƒ¹æ ¼åˆ†ä½ˆï¼ˆHistogramï¼‰")
            import matplotlib.pyplot as plt
            fig, ax = plt.subplots()
            ax.hist(filtered["_price_num"].dropna().astype(float), bins=20)
            ax.set_xlabel("price")
            ax.set_ylabel("count")
            st.pyplot(fig)
        elif "category" in filtered.columns:
            st.caption("åˆ†é¡å‰å (è‹¥ç„¡åƒ¹æ ¼æ¬„ä½)")
            st.bar_chart(filtered["category"].value_counts().head(10))
        else:
            st.info("ç„¡åƒ¹æ ¼æˆ–åˆ†é¡æ¬„å¯è¦–è¦ºåŒ–ã€‚")

    # Optional: time trend if date available
    if "_date_dt" in filtered.columns and filtered["_date_dt"].notna().any():
        st.caption("æ™‚é–“åºåˆ—ï¼šå„æ—¥æœŸç­†æ•¸")
        daily = filtered.copy()
        daily["_d"] = daily["_date_dt"].dt.date
        st.line_chart(daily["_d"].value_counts().sort_index())

    # ---------------------
    # Data table + download
    # ---------------------
    st.subheader("ğŸ“„ è³‡æ–™è¡¨")
    show_cols = [c for c in ["source","id","title","url","author","category","date","price","value"] if c in filtered.columns]
    if "pk" in filtered.columns: show_cols = ["pk"] + show_cols
    st.dataframe(filtered[show_cols].reset_index(drop=True), use_container_width=True, height=350)
    st.download_button(
        "ä¸‹è¼‰éæ¿¾å¾Œ CSV",
        data=filtered[show_cols].to_csv(index=False).encode("utf-8"),
        file_name="filtered_snapshot.csv",
        mime="text/csv"
    )

# ---------------------
# Diff summary & images
# ---------------------
st.subheader("Diff Summaryï¼ˆæœ€æ–°ä¸€æ¬¡ï¼‰")
summary_path = diff_dir / "summary.json"
if summary_path.exists():
    try:
        summary = json.loads(summary_path.read_text())
    except Exception as e:
        st.error(f"è®€å– summary.json å¤±æ•—ï¼š{e}")
        summary = None

    if summary:
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("æ–°å¢ new", int(summary.get("new", 0)))
        m2.metric("åˆªé™¤ deleted", int(summary.get("deleted", 0)))
        m3.metric("ä¿®æ”¹ changed", int(summary.get("changed", 0)))
        m4.metric("æ—¥æœŸ", summary.get("date", "-"))

        # show generated bar image (pipeline.diff.chart_summary)
        charts = _latest_chart_images()
        if charts:
            st.image(str(charts[-1]), caption=charts[-1].name, use_container_width=True)
        else:
            # fallback inline bar
            st.info("æ‰¾ä¸åˆ° charts/summary_*.pngï¼Œä»¥ä¸‹ç‚ºå³æ™‚ç”Ÿæˆçš„ç°¡æ˜“é•·æ¢åœ–ï¼š")
            df_bar = pd.DataFrame({
                "type": ["new", "deleted", "changed"],
                "count": [summary.get("new",0), summary.get("deleted",0), summary.get("changed",0)]
            })
            st.bar_chart(df_bar.set_index("type"))

        # Try to locate latest diff CSVs by stamp
        stamp = summary.get("date","")
        new_csv = diff_dir / f"diff_{stamp}_new.csv"
        del_csv = diff_dir / f"diff_{stamp}_deleted.csv"
        # changed is currently not saved as CSV by pipeline; list is in memory only.

        exp = st.expander("æŸ¥çœ‹ New / Deleted æ˜ç´°ï¼ˆè‹¥å­˜åœ¨ï¼‰")
        with exp:
            if new_csv.exists():
                st.caption(f"New: {new_csv.name}")
                st.dataframe(_read_csv_safe(new_csv), use_container_width=True, height=200)
            else:
                st.info("æœªæ‰¾åˆ°å°æ‡‰çš„ new CSVã€‚")

            if del_csv.exists():
                st.caption(f"Deleted: {del_csv.name}")
                st.dataframe(_read_csv_safe(del_csv), use_container_width=True, height=200)
            else:
                st.info("æœªæ‰¾åˆ°å°æ‡‰çš„ deleted CSVã€‚")
else:
    st.info("No diff summary yet. è«‹å…ˆåŸ·è¡Œ `python -m src.interface.cli diff ...` å¾Œå†å›ä¾†çœ‹ã€‚")
